# ReviewSense AI ğŸ§ ğŸ“Š

[![CI](https://github.com/Gujjar-Pranav/review-sense-ai/actions/workflows/ci.yml/badge.svg)](https://github.com/Gujjar-Pranav/review-sense-ai/actions/workflows/ci.yml)

ğŸ”— **Live App:** https://reviewsense-ai.streamlit.app  
*(If sleeping, open once to wake it up)*

---

**ReviewSense AI** is a trust-aware review intelligence dashboard that transforms raw customer reviews into **clear insights, risks, and actions**.  
It combines machine learning, confidence scoring, and explainable analytics to help teams understand *what customers feel*, *where the model is uncertain*, and *what needs human attention*.

---

## ğŸš€ What This Project Does

ReviewSense AI analyzes customer reviews (Amazon-style) and provides:

- Sentiment classification (Positive / Negative / Mixed)
- Confidence & risk scoring for each prediction
- Identification of **tricky reviews** where AI struggles
- Executive-level insights for decision-makers
- A polished, interactive **Streamlit dashboard**

This project is designed to be both **ML-practical** and **business-ready**.

---

## ğŸ§© Key Features

### ğŸ›¡ï¸ Trust & Confidence Dashboard
- Negative risk percentage
- Low-confidence review detection
- Auto-approve vs manual-review zones
- Clear operational recommendations

### ğŸ§ª Tricky Reviews (AI Limitations)
Detects reviews that are hard for AI to judge, including:
- Mixed sentiment
- Negation (e.g. *"not bad"*)
- Confusing or vague wording
- Strong tone / emphasis (caps, punctuation)
- Uncertain or borderline predictions

### ğŸ“Š Business Insights (Executive View)
- Overall sentiment distribution
- Focus index (where to fix first)
- Top praise themes
- Example high-confidence praise & complaints
- Shareable plain-English summary

### ğŸ” Drilldowns & Transparency
- Filter by confidence threshold
- Category-based analysis
- Download-ready results table
- Clear explanation of why reviews need human review

---

## ğŸ§  Machine Learning Pipeline

- Text preprocessing & TF-IDF feature extraction
- Calibrated sentiment modeling
- Probability-based confidence scoring
- Error analysis and misclassification reports
- Model comparison utilities

---

## ğŸ› ï¸ Tech Stack

- **Python 3.12**
- **Streamlit** â€“ interactive dashboard
- **scikit-learn** â€“ ML models & calibration
- **pandas / numpy** â€“ data processing
- **Plotly** â€“ rich visualizations
- **Joblib** â€“ model persistence

---

## ğŸ“‚ Project Structure

```text
review-sense-ai/
â”‚
â”œâ”€â”€ app/                    # Streamlit UI
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â”œâ”€â”€ ui_helpers.py
â”‚   â””â”€â”€ visualizations.py
â”‚
â”œâ”€â”€ src/                    # ML & analysis pipeline
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ calibrate_train.py
â”‚   â”œâ”€â”€ modeling_compare.py
â”‚   â”œâ”€â”€ error_analysis.py
â”‚   â”œâ”€â”€ eda.py
â”‚   â”œâ”€â”€ data_load.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ artifacts/              # Trained model (committed)
â”‚   â””â”€â”€ best_model_calibrated.joblib
â”‚
â”œâ”€â”€ outputs/reports/        # Evaluation artifacts
â”‚   â”œâ”€â”€ misclassified.csv
â”‚   â”œâ”€â”€ model_comparison.csv
â”‚   â””â”€â”€ calibrated_metrics.json
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ amazonreviews.tsv
â”‚
â”œâ”€â”€ .github/workflows/ci.yml
â”œâ”€â”€ .streamlit/config.toml
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ runtime.txt
â””â”€â”€ README.md

â–¶ï¸ How to Run Locally
1ï¸âƒ£ Clone the repository
git clone https://github.com/Gujjar-Pranav/review-sense-ai.git
cd review-sense-ai

2ï¸âƒ£ Create & activate virtual environment
python -m venv .venv
source .venv/bin/activate   # macOS / Linux
# .venv\Scripts\activate    # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ (Optional) Regenerate model & reports
python main.py

5ï¸âƒ£ Run the Streamlit app
streamlit run app/streamlit_app.py

ğŸ“ˆ Example Use Cases

Product teams prioritizing customer pain points

Analysts auditing ML confidence and failure modes

Businesses deciding when AI decisions need human review

Portfolio demonstration of Responsible AI design

ğŸ”’ Responsible AI Focus

ReviewSense AI explicitly highlights:

Where the model is uncertain

Why human review is required

How to safely operationalize ML predictions

This makes it suitable for real-world, high-stakes ML use cases.

ğŸ§ª CI/CD & Quality Gates

This repository includes production-grade CI/CD:

âœ… GitHub Actions CI

âœ… Ruff linting (PEP8 + modern Python)

âœ… Python compile checks

âœ… Artifact presence validation

âœ… Fail-fast safety checks

All commits to main must pass CI before merging.

ğŸ“Œ Future Improvements

Model monitoring over time

Topic modeling for complaints

Multi-language support

A/B evaluation dashboard

Drift & confidence alerts

ğŸ‘¤ Author

Pranav Gujjar
Machine Learning & Data Science
