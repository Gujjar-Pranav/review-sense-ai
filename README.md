# ğŸ’¬ ReviewSense AI  
[![CI](https://github.com/Gujjar-Pranav/review-sense-ai/actions/workflows/ci.yml/badge.svg)](https://github.com/Gujjar-Pranav/review-sense-ai/actions/workflows/ci.yml)

**A customer-ready AI dashboard that transforms product reviews into clear insights, risks, and actions.**

---

## ğŸš€ Overview

**ReviewSense AI** is an end-to-end **review intelligence platform** that analyzes customer feedback using machine learning and presents:

- Sentiment insights (Positive / Negative / Uncertain)
- Model confidence & calibration
- Misclassification analysis
- Executive-friendly dashboards
- Explainable AI outputs (simple + technical modes)

Built with **production discipline**: CI/CD, linting, artifact validation, and Streamlit Cloud deployment.

---

## ğŸ§  Key Features

- âœ… Calibrated sentiment classifier (high/low confidence)
- ğŸ“Š Model comparison (TF-IDF vs BERT)
- ğŸ” Misclassified review analysis
- ğŸ§¾ Explainable highlights (positive / negative phrases)
- ğŸ› Simple vs Technical explanation mode
- ğŸŒ™ Premium dark theme (executive-ready UI)
- â˜ï¸ Streamlit Cloud compatible (no training at runtime)
- ğŸ›¡ Hardened CI/CD with Ruff linting

---

## ğŸ— Project Structure

review-sense-ai/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ streamlit_app.py # Streamlit dashboard
â”‚ â”œâ”€â”€ ui_helpers.py
â”‚ â””â”€â”€ visualizations.py
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ config.py # Central paths & constants
â”‚ â”œâ”€â”€ data_load.py
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”œâ”€â”€ modeling_compare.py
â”‚ â”œâ”€â”€ calibrate_train.py
â”‚ â”œâ”€â”€ error_analysis.py
â”‚ â””â”€â”€ utils.py
â”œâ”€â”€ artifacts/
â”‚ â””â”€â”€ best_model_calibrated.joblib
â”œâ”€â”€ data/
â”‚ â””â”€â”€ amazonreviews.tsv
â”œâ”€â”€ outputs/
â”‚ â””â”€â”€ reports/
â”‚ â”œâ”€â”€ model_comparison.csv
â”‚ â”œâ”€â”€ misclassified.csv
â”‚ â”œâ”€â”€ calibrated_metrics.json
â”‚ â””â”€â”€ misclassified_summary.json
â”œâ”€â”€ .github/workflows/ci.yml
â”œâ”€â”€ .streamlit/config.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ runtime.txt
â””â”€â”€ README.md

markdown
Copy code

---

## ğŸ§ª Machine Learning Pipeline

1. **Data ingestion** (Amazon-style reviews)
2. **Text preprocessing**
3. **Model comparison**
   - TF-IDF + Linear models
   - BERT embeddings
4. **Final model selection**
5. **Probability calibration**
6. **Error analysis & reports**
7. **Artifact persistence**

> âš ï¸ Training is done **locally only**.  
> Streamlit Cloud runs in **inference-only mode** for stability.

---

## â–¶ï¸ Run Locally

### 1ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
2ï¸âƒ£ Train model & generate reports
bash
Copy code
python main.py
This generates:

artifacts/best_model_calibrated.joblib

outputs/reports/*.csv

3ï¸âƒ£ Launch dashboard
bash
Copy code
streamlit run app/streamlit_app.py
â˜ï¸ Streamlit Cloud Deployment
App runs without training

Requires:

artifacts/best_model_calibrated.joblib

outputs/reports/ (recommended)

Missing files show guided UI warnings, not crashes

ğŸ›¡ CI / CD
Automated GitHub Actions pipeline:

Ruff lint (PEP8 + best practices)

Python compilation check

Artifact validation

Optional tests (if present)

CI fails on:

Unused imports

Bad boolean comparisons

Missing required artifacts

ğŸ¨ UI & Theming
Executive dark theme

High-contrast highlights

Clean chip-based explanations

Accessible color palette

Wide-screen optimized layout

Theme controlled via:

arduino
Copy code
.streamlit/config.toml
ğŸ“Œ Why This Project Matters
This is not a demo.

It demonstrates:

Real ML lifecycle

Explainable AI

Production hygiene

CI/CD discipline

Cloud deployment constraints

Executive-grade UX

Perfect for:

ML Engineer portfolios

Data Science interviews

Product-AI showcases

ğŸ‘¤ Author
Pranav Gujjar
Machine Learning Engineer
